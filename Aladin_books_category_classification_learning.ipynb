{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Aladin_books_category_classification_learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1q6TWDTuwiDtmGMEhzhWmvVxuNRHpplSy",
      "authorship_tag": "ABX9TyMoT6TAokM/Pb4TFJjEQvZu"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1Mk_ji4lKn4"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import *"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTFAV6fZlj9W",
        "outputId": "7757d4ff-718f-430e-f185-62924b25ca28"
      },
      "source": [
        "# 넘파이 데이터 불러오기\n",
        "X_train, X_test, Y_train, Y_test = np.load(\n",
        "    '/content/drive/MyDrive/Colab Notebooks/datas/books_data_max_970_size_131128.npy',\n",
        "    allow_pickle=True)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_train.shape)\n",
        "print(Y_test.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(49524, 970)\n",
            "(8740, 970)\n",
            "(49524, 8)\n",
            "(8740, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlPeM0aYmYat",
        "outputId": "a22aa51a-8698-4428-da51-330af4e63cc8"
      },
      "source": [
        "model = Sequential() \n",
        "model.add(Embedding(131128, 200, input_length=970))\n",
        "# Embedding : 벡터라이징을 해주는 함수, input_length : 문장은 길이만 있기에 length\n",
        "model.add(Conv1D(32, kernel_size=5,\n",
        "                 padding='same', activation='relu')) # 문장의 관계 Conv1D\n",
        "model.add(MaxPool1D(pool_size=1))\n",
        "# 순서가 있는 데이터, LSTM 사용\n",
        "model.add(LSTM(128, activation='tanh',\n",
        "               return_sequences = True))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(LSTM(64, activation='tanh',\n",
        "               return_sequences = True))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(8, activation='softmax')) # 다중분류기 softmax를 사용하여 확률값으로\n",
        "print(model.summary())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 970, 200)          26225600  \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 970, 32)           32032     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1 (None, 970, 32)           0         \n",
            "_________________________________________________________________\n",
            "lstm_6 (LSTM)                (None, 970, 128)          82432     \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 970, 128)          0         \n",
            "_________________________________________________________________\n",
            "lstm_7 (LSTM)                (None, 970, 64)           49408     \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 970, 64)           0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 62080)             0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 128)               7946368   \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 8)                 520       \n",
            "=================================================================\n",
            "Total params: 34,344,616\n",
            "Trainable params: 34,344,616\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_ycd6gCqK0g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aebee47d-90bc-4201-c605-54e3d9f7b145"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam', metrics=['accuracy'])\n",
        "fit_hist = model.fit(X_train, Y_train, batch_size=256,\n",
        "                     epochs=5, validation_data=(X_test, Y_test))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "194/194 [==============================] - 100s 503ms/step - loss: 0.9043 - accuracy: 0.6681 - val_loss: 0.4163 - val_accuracy: 0.8696\n",
            "Epoch 2/5\n",
            "194/194 [==============================] - 97s 501ms/step - loss: 0.2474 - accuracy: 0.9248 - val_loss: 0.3661 - val_accuracy: 0.8843\n",
            "Epoch 3/5\n",
            "194/194 [==============================] - 98s 503ms/step - loss: 0.0914 - accuracy: 0.9736 - val_loss: 0.4235 - val_accuracy: 0.8838\n",
            "Epoch 4/5\n",
            "194/194 [==============================] - 97s 502ms/step - loss: 0.0413 - accuracy: 0.9884 - val_loss: 0.5169 - val_accuracy: 0.8812\n",
            "Epoch 5/5\n",
            "194/194 [==============================] - 98s 503ms/step - loss: 0.0236 - accuracy: 0.9936 - val_loss: 0.6113 - val_accuracy: 0.8768\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkJGoA1hx9Fr",
        "outputId": "e52773bc-bac2-4c1a-b660-501e626ba573"
      },
      "source": [
        "score = model.evaluate(X_test, Y_test)\n",
        "print(score[1])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "274/274 [==============================] - 10s 37ms/step - loss: 0.6113 - accuracy: 0.8768\n",
            "0.876773476600647\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkFdv0UkxMfN"
      },
      "source": [
        "model.save('/content/models/news_classification_{}.h5'.format(score[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SH46S6varCcU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}